export const questionData = [
  {
    question: "The term of 'Data Democracy,' what is that relevant to in Big Data?",
    options: [
      "It allows everyone in an organization to access and understand data",
      "Big data analytic is more accurate than small data analytic",
      "It refers to the use of AI in analytics",
      "It means restricting data access to data engineers only"
    ],
    answer: "It allows everyone in an organization to access and understand data"
  },
  {
    question: "What is the correct sorting of computing platforms by data size and network connectivity?",
    options: [
      "Standalone Computing, Distributed Computing, Cloud Computing, Ambient Computing",
      "Distributed Computing, Cloud Computing, Standalone Computing, Ambient Computing",
      "Cloud Computing, Distributed Computing, Standalone Computing, Ambient Computing",
      "Standalone Computing, Cloud Computing, Distributed Computing, Ambient Computing"
    ],
    answer: "Standalone Computing, Distributed Computing, Cloud Computing, Ambient Computing"
  },
  {
    question: "What is not the responsibility of a Big Data engineer?",
    options: [
      "Designing the data dashboard",
      "Developing data pipelines",
      "Managing data storage systems",
      "Implementing data processing solutions"
    ],
    answer: "Designing the data dashboard"
  },
  {
    question: "According to Big Data pipeline tasks, what is not a task of a Big Data engineer?",
    options: [
      "All tasks listed are tasks of a Big Data engineer",
      "Data collection",
      "Data transformation",
      "Data loading"
    ],
    answer: "All tasks listed are tasks of a Big Data engineer"
  },
  {
    question: "Big Data processing is not...",
    options: [
      "Centralized computing",
      "Distributed computing",
      "Parallel processing",
      "In-memory processing"
    ],
    answer: "Centralized computing"
  },
  {
    question: "Which answer is true about Hive?",
    options: [
      "Hive is a query engine for Big Data",
      "Hive is a NoSQL database",
      "Hive is a data storage format",
      "Hive is a streaming tool"
    ],
    answer: "Hive is a query engine for Big Data"
  },
  {
    question: "Why does Hive need a metastore?",
    options: [
      "To store table metadata and schema information",
      "To execute Hive queries faster",
      "To connect to Spark directly",
      "To cache MapReduce jobs"
    ],
    answer: "To store table metadata and schema information"
  },
  {
    question: "Which is not true about the differences between external and internal tables in Hive?",
    options: [
      "There are two correct answers",
      "Idk",
      "Idk",
      "Idk"
    ],
    answer: "There are two correct answers"
  },
  {
    question: "Which statement is not true about Hive and Impala?",
    options: [
      "Hive is more efficient than Impala",
      "Impala executes queries faster than Hive",
      "Hive supports batch processing",
      "Impala is suitable for interactive queries"
    ],
    answer: "Hive is more efficient than Impala"
  },
  {
    question: "Which programming language is not supported by Spark?",
    options: ["C", "Python", "Java", "Scala"],
    answer: "C"
  },
  {
    question: "In the Hadoop Ecosystem, Spark can be compared to...",
    options: [
      "MR (MapReduce)",
      "Hive",
      "Pig",
      "Oozie"
    ],
    answer: "MR (MapReduce)"
  },
  {
    question: "Spark claims to be faster than MapReduce; what is the reason?",
    options: [
      "It is an in-memory processing system",
      "It uses more nodes than Hadoop",
      "It supports only Python",
      "It compresses data automatically"
    ],
    answer: "It is an in-memory processing system"
  },
  {
    question: "Which answer is not true about actions and transformations in Spark?",
    options: [
      "There are two correct answers",
      "idk",
      "idk",
      "idk"
    ],
    answer: "There are two correct answers"
  },
  {
    question: "Which answer is true about the DataFrame in Spark?",
    options: [
      "All provided answers are correct",
      "DataFrames provide optimized execution",
      "DataFrames have schema",
      "DataFrames can be created from RDDs"
    ],
    answer: "All provided answers are correct"
  },
  {
    question: "Which one of the following commands can cause a data shuffling operation in Spark?",
    options: [
      "groupBy()",
      "take()",
      "map()",
      "filter()"
    ],
    answer: "groupBy()"
  },
  {
    question: "Which of the following is not a way to create a DataFrame in Spark?",
    options: [
      "Parallelizing a Python list",
      "Loading data from CSV or JSON files",
      "Reading from an existing RDD",
      "Using external data sources like Hive"
    ],
    answer: "Parallelizing a Python list"
  },
  {
    question: "What is the goal of Impact Analysis?",
    options: [
      "To understand how data affects other data within a system",
      "To optimize storage usage",
      "To clean corrupted data",
      "To compress redundant data"
    ],
    answer: "To understand how data affects other data within a system"
  },
  {
    question: "If an organization wants to gather data from all departments to create main data, which data governance aspect applies?",
    options: [
      "Data Integration and Interoperability",
      "Data Privacy and Security",
      "Data Quality Management",
      "Data Stewardship"
    ],
    answer: "Data Integration and Interoperability"
  },
  {
    question: "What is the difference between Data Inventory and Data Catalog?",
    options: [
      "Data Inventory focuses on where and how data is stored, while Data Catalog focuses on what data is stored and its business meaning",
      "Data Catalog stores data, while Data Inventory analyzes it",
      "Data Inventory is part of data visualization",
      "Both are used for data security only"
    ],
    answer: "Data Inventory focuses on where and how data is stored, while Data Catalog focuses on what data is stored and its business meaning"
  },
  {
    question: "Which choice correctly describes Data Quality in Data Governance?",
    options: [
      "It is the measurement of accuracy, completeness, and consistency of the data",
      "It measures the storage efficiency",
      "It defines the ownership of data",
      "It checks system performance"
    ],
    answer: "It is the measurement of accuracy, completeness, and consistency of the data"
  },
  {
    question: "In a data governance structure, which role is responsible for enforcing data policies in the organization?",
    options: [
      "Data Steward",
      "Data Analyst",
      "Data Scientist",
      "Database Administrator"
    ],
    answer: "Data Steward"
  },
  {
    question: "Which one of these is not a core feature of Atlas?",
    options: [
      "Data access control",
      "Metadata management",
      "Data lineage tracking",
      "Data classification"
    ],
    answer: "Data access control"
  },
  {
    question: "Which software is not used for Big Data governance?",
    options: [
      "Thanos",
      "Apache Atlas",
      "Collibra",
      "Alation"
    ],
    answer: "Thanos"
  },
  {
    question: "This course aims to train you to become...?",
    options: [
      "A Big Data engineer",
      "A Data Analyst",
      "A Database Administrator",
      "A Software Tester"
    ],
    answer: "A Big Data engineer"
  },
  {
    question: "How does Sqoop define data types when importing data from RDBMS to HDFS?",
    options: [
      "By mapping SQL types to Java types",
      "By using CSV schema files",
      "By automatic JSON parsing",
      "By Hadoop configuration only"
    ],
    answer: "By mapping SQL types to Java types"
  },
  {
    question: "What is incorrect about the Sqoop tool?",
    options: [
      "Sqoop cannot import data to Flume, Hive, and HBase simultaneously",
      "Sqoop can import data from MySQL",
      "Sqoop supports incremental imports",
      "Sqoop works with MapReduce"
    ],
    answer: "Sqoop cannot import data to Flume, Hive, and HBase simultaneously"
  },
  {
    question: "What is incorrect about Direct Mode in Sqoop?",
    options: [
      "Direct Mode does not require a JDBC connection in the command",
      "Direct Mode improves performance",
      "Direct Mode is database-specific",
      "Direct Mode can be used with MySQL"
    ],
    answer: "Direct Mode does not require a JDBC connection in the command"
  },
  {
    question: "What does the -m option in Apache Sqoop specify?",
    options: [
      "The number of MapReduce processes",
      "The memory limit for jobs",
      "The number of reducers",
      "The number of columns"
    ],
    answer: "The number of MapReduce processes"
  },
  {
    question: "What is correct about the --split-by option in Sqoop?",
    options: [
      "It is used to specify a column for dividing records, not just the primary key",
      "It must always be the primary key",
      "It splits by file size only",
      "It is used for output compression"
    ],
    answer: "It is used to specify a column for dividing records, not just the primary key"
  },
  {
    question: "What is incorrect about the Flume tool?",
    options: [
      "A Flume agent can work without a Flume Channel",
      "Flume collects and moves log data",
      "Flume supports multi-hop flow",
      "Flume uses sources, channels, and sinks"
    ],
    answer: "A Flume agent can work without a Flume Channel"
  },
  {
    question: "What type of data flow is shown in this picture (by definition of Flume)?",
    options: [
      "Multi-hop Flow",
      "Simple Flow",
      "Consolidated Flow",
      "Fan-in Flow"
    ],
    answer: "Multi-hop Flow",
    image: "/images/q31_BigData-M1_jtm.png"
  },
  {
    question: "What is incorrect about Flume?",
    options: [
      "A sink can read from one or more channels",
      "A source sends events to channels",
      "A channel stores events temporarily",
      "A sink delivers events to destinations"
    ],
    answer: "A sink can read from one or more channels"
  },
  {
    question: "Which type of source is most commonly used to receive data from other Flume agents?",
    options: [
      "AVRO",
      "SYSLOG",
      "HTTP",
      "NETCAT"
    ],
    answer: "AVRO"
  },
  {
    question: "According to the 'cheat sheet' for Flume batch size tuning, what is the recommended batchSize for a source using HDFS sink type?",
    options: [
      "200",
      "1000",
      "50",
      "500"
    ],
    answer: "200",
    image: "/images/q34-BigData-M1_jtm.png"
  },
  {
    question: "What does the crontab line '5 5 * * * /opt/getdata.sh' mean?",
    options: [
      "It runs the batch file /opt/getdata.sh at 5:05 AM every day",
      "It runs the file every 5 minutes",
      "It runs every 5 hours",
      "It runs on the 5th day of each month"
    ],
    answer: "It runs the batch file /opt/getdata.sh at 5:05 AM every day"
  },
  {
    question: "What is correct about Oozie?",
    options: [
      "Oozie is a tool for managing workflows in Hadoop",
      "Oozie is used for storing large datasets",
      "Oozie is a data streaming tool",
      "Oozie is a visualization platform"
    ],
    answer: "Oozie is a tool for managing workflows in Hadoop"
  },
  {
    question: "What is incorrect about Apache Oozie?",
    options: [
      "No answer is wrong",
      "It coordinates Hadoop jobs",
      "It supports time-based scheduling",
      "It can run MapReduce and Pig jobs"
    ],
    answer: "No answer is wrong"
  },
  {
    question: "Which is not a type of Oozie Job?",
    options: [
      "Oozie Jobs",
      "MapReduce Job",
      "Pig Job",
      "Hive Job"
    ],
    answer: "Oozie Jobs"
  },
  {
    question: "Which is not a type of Control Flow node in Oozie?",
    options: [
      "Stop",
      "Start",
      "End",
      "Decision"
    ],
    answer: "Stop"
  },
  {
    question: "What is incorrect about Airflow?",
    options: [
      "Airflow cannot be integrated with the Hadoop ecosystem",
      "Airflow supports DAG-based scheduling",
      "Airflow has web UI",
      "Airflow is open-source"
    ],
    answer: "Airflow cannot be integrated with the Hadoop ecosystem"
  },
  {
    question: "Which Airflow component uses the DAG object to decide tasks that need to be run?",
    options: [
      "Scheduler component",
      "Executor component",
      "Webserver component",
      "Worker component"
    ],
    answer: "Scheduler component"
  },
  {
    question: "Which Airflow component stores the states?",
    options: [
      "Metadata database component",
      "Scheduler",
      "Executor",
      "Webserver"
    ],
    answer: "Metadata database component"
  },
  {
    question: "How many executors can handle tasks in Local Execution mode in Airflow?",
    options: [
      "Depends on the machine's resources",
      "Only one executor",
      "Two executors maximum",
      "Unlimited executors"
    ],
    answer: "Depends on the machine's resources"
  },
  {
    question: "In Celery Executor mode in Airflow, which component stores commands for execution?",
    options: [
      "Broker component",
      "Scheduler",
      "Webserver",
      "Metadata database"
    ],
    answer: "Broker component"
  },
  {
    question: "What is wrong about On-Premise and On-Cloud?",
    options: [
      "No answer is wrong",
      "On-Premise requires physical infrastructure",
      "Cloud offers scalable resources",
      "Cloud reduces hardware maintenance"
    ],
    answer: "No answer is wrong"
  },
  {
    question: "Why are data important in decision-making?",
    options: [
      "Because they contain the business status",
      "Because they replace managers",
      "Because they reduce all risks",
      "Because they guarantee profit"
    ],
    answer: "Because they contain the business status"
  }
];

export default questionData;
